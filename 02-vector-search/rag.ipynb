{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73a33b6e-868c-4bc5-8c28-b810692dfd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "from fastembed import TextEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14c8e8d7-ae57-4d65-ba5f-6b0a55da3eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "qd_client = QdrantClient('http://localhost:6333')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31717f56-2790-4e1e-832c-ec1e00c6719b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('documents.json', 'r') as documents_file:\n",
    "    documents_raw = json.load(documents_file)\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course_dict in documents_raw:\n",
    "    for doc in course_dict['documents']:\n",
    "        doc['course'] = course_dict['course']\n",
    "        documents.append(doc)\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fdebc0f-d2c7-4082-b488-437125e02bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_handle = \"jinaai/jina-embeddings-v2-small-en\"\n",
    "collection_name = \"zoomcamp-faq\"\n",
    "EMBEDDING_DIMENSIONALITY = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d30881a8-863b-4026-a42a-5fdd84c9ff3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qd_client.delete_collection(collection_name=collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c2c43f2-6673-4252-b626-920685c1cacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qd_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=EMBEDDING_DIMENSIONALITY,\n",
    "        distance=models.Distance.COSINE\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7da21da-aff3-47d7-9e3e-4d0609e3e9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "\n",
    "for i, doc in enumerate(documents):\n",
    "    text = doc['question'] + ' ' + doc['text']\n",
    "    vector = models.Document(text=text, model=model_handle)\n",
    "    point = models.PointStruct(\n",
    "        id = i,\n",
    "        vector = vector,\n",
    "        payload = doc\n",
    "    )\n",
    "    points.append(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50d3b6c4-45dc-4130-bf24-7113763db2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qd_client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=points\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2bd8f581-799c-4ff5-abc3-84d7804d3efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# The client gets the API key from the environment variable `GEMINI_API_KEY`.\n",
    "genai_client = genai.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5cd824d2-1a80-41a6-8fc7-fdba19fba0f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=6, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qd_client.create_payload_index(\n",
    "    collection_name=collection_name,\n",
    "    field_name=\"course\",\n",
    "    field_schema=\"keyword\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f4fef642-40e2-4d1d-b6b8-564a57abf81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'I just discovered this course. Can I still join it?'\n",
    "limit = 5\n",
    "course = 'data-engineering-zoomcamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1862b98b-8617-46ff-9ba3-184098ac1f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search(question, limit=1, course='data-engineering-zoomcamp'):\n",
    "    query_points = qd_client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=models.Document( #embed the query text locally with \"jinaai/jina-embeddings-v2-small-en\"\n",
    "            text=question,\n",
    "            model=model_handle\n",
    "        ),\n",
    "        query_filter=models.Filter(\n",
    "            must=[\n",
    "                models.FieldCondition(\n",
    "                    key=\"course\",\n",
    "                    match=models.MatchValue(value=course)\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        limit=limit, # top closest matches\n",
    "        with_payload=True #to get metadata in the results\n",
    "    )\n",
    "    results = []\n",
    "    for point in query_points.points:\n",
    "        results.append(point.payload)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5df15342-13b7-434d-a003-010e7359402a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'In the project directory, run:\\njava -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Java Kafka: How to run producer/consumer/kstreams/etc in terminal',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'For example, when running JsonConsumer.java, got:\\nConsuming form kafka started\\nRESULTS:::0\\nRESULTS:::0\\nRESULTS:::0\\nOr when running JsonProducer.java, got:\\nException in thread \"main\" java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.SaslAuthenticationException: Authentication failed\\nSolution:\\nMake sure in the scripts in src/main/java/org/example/ that you are running (e.g. JsonConsumer.java, JsonProducer.java), the StreamsConfig.BOOTSTRAP_SERVERS_CONFIG is the correct server url (e.g. europe-west3 from example vs europe-west2)\\nMake sure cluster key and secrets are updated in src/main/java/org/example/Secrets.java (KAFKA_CLUSTER_KEY and KAFKA_CLUSTER_SECRET)',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Java Kafka: When running the producer/consumer/etc java scripts, no results retrieved or no message sent',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'If you have this error, it most likely that your kafka broker docker container is not working.\\nUse docker ps to confirm\\nThen in the docker compose yaml file folder, run docker compose up -d to start all the instances.',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'kafka.errors.NoBrokersAvailable: NoBrokersAvailable',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': \"Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\\nTo create a virtual env and install packages (run only once)\\npython -m venv env\\nsource env/bin/activate\\npip install -r ../requirements.txt\\nTo activate it (you'll need to run it every time you need the virtual env):\\nsource env/bin/activate\\nTo deactivate it:\\ndeactivate\\nThis works on MacOS, Linux and Windows - but for Windows the path is slightly different (it's env/Scripts/activate)\\nAlso the virtual environment should be created only to run the python file. Docker images should first all be up and running.\",\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Module “kafka” not found when trying to run producer.py',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': \"Below I have listed some steps I took to rectify this and potentially other minor errors, in Windows:\\nUse the git bash terminal in windows.\\nActivate python venv from git bash: source .venv/Scripts/activate\\nModify the seed_kafka.py file: in the first line, replace python3 with python.\\nNow from git bash, run the seed-kafka cmd. It should work now.\\nAdditional Notes:\\nYou can connect to the RisingWave cluster from Powershell with the command psql -h localhost -p 4566 -d dev -U root , otherwise it asks for a password.\\nThe equivalent of source commands.sh  in Powershell is . .\\\\commands.sh from the workshop directory.\\nHope this can save you from some trouble in case you're doing this workshop on Windows like I am.\\n—--------------------------------------------------------------------------------------\",\n",
       "  'section': 'Workshop 2 - RisingWave',\n",
       "  'question': 'Psycopg2 InternalError: Failed to run the query - when running the seed-kafka command after initial setup.',\n",
       "  'course': 'data-engineering-zoomcamp'}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = vector_search(question='How do I run Kafka?', limit=5)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a5450dc6-d8d8-43a5-b9e1-0cabca611783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "If the CONTEXT doesn't contain the answer, output NONE\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\"\n",
    "\n",
    "    prompt = prompt_template.format(question=query, context=context)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b7457096-2a47-4845-ac48-dd827c0a3c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    contents = types.Content(\n",
    "      role='user',\n",
    "      parts=[types.Part.from_text(text=prompt)]\n",
    "    )\n",
    "    \n",
    "    response = genai_client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\", contents=contents\n",
    "    )\n",
    "\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5399de45-b0c9-4aef-aed6-3202007b4ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = vector_search(question=query, limit=5)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5bdbf362-75c1-486b-b5a0-87628bfa81c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To run Kafka:\\n\\n1.  **Ensure Kafka Broker is running**: If you encounter a `NoBrokersAvailable` error, it likely means your Kafka broker Docker container is not working. Use `docker ps` to confirm, then navigate to the docker compose yaml file folder and run `docker compose up -d` to start all instances.\\n2.  **Run Java Kafka client applications (e.g., producer/consumer)**: In the project directory, run:\\n    `java -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java`\\n    (Replace `<jar_name>` with the appropriate jar name, and `JsonProducer.java` with the specific script you want to run).\\n3.  **Run Python Kafka client applications (e.g., producer.py)**: Create and activate a virtual environment, then run your Python files within it.\\n    *   To create and install packages (run once):\\n        `python -m venv env`\\n        `source env/bin/activate` (or `env/Scripts/activate` on Windows)\\n        `pip install -r ../requirements.txt`\\n    *   To activate the virtual environment (run every time needed):\\n        `source env/bin/activate` (or `env/Scripts/activate` on Windows)\\n    *   After activation, you can run your Python script (e.g., `python producer.py`).'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag('How do I run Kafka?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50540081-3799-4d1a-a07f-b9c377fb5055",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
